{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "* Check for commas in the data in query and replace all with a special character\n",
    "* More efficient get_columns() call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Specific data queries'''\n",
    "\n",
    "def get_columns(schema, table):\n",
    "    # Start a timer\n",
    "    start = time.time()\n",
    "    \n",
    "    query = pd.read_sql_query('SELECT TOP 1 * FROM '+schema+\".\"+table+';', ENGINE)\n",
    "    return query.columns, \"\\n Time it took in seconds: \" + str(time.time() - start)\n",
    "\n",
    "def get_data(schema, table, columns, start_date, end_date, filters, groupings=False):\n",
    "    start = time.time()\n",
    "    \n",
    "    params_list = []\n",
    "    params_list.append(start_date)\n",
    "    params_list.append(end_date)\n",
    "    \n",
    "    columns_as_string = ', '.join(columns)\n",
    "    \n",
    "    filters_query_list = []\n",
    "    \n",
    "    for i in filters:\n",
    "        filters_query_list.append(' AND '+i+' = %s')\n",
    "        params_list.append(str(filters[i]))\n",
    "    \n",
    "    filters_query_string = \"\".join(filters_query_list)\n",
    "    \n",
    "    print(columns_as_string)\n",
    "    print(params_list)\n",
    "    \n",
    "    query = pd.read_sql_query(\n",
    "        'SELECT '+columns_as_string+' FROM '+schema+\".\"+table+\n",
    "        ' WHERE report_date BETWEEN %s AND %s'+filters_query_string+';', ENGINE, params=params_list)\n",
    "    \n",
    "    return query, \"\\n Time it took in seconds: \" + str(time.time() - start)\n",
    "    \n",
    "\n",
    "def get_nm_test2(schema, table, start_date, end_date):\n",
    "    '''Creates the Pkl file.\n",
    "    Schema should be a string of the schema desired'''\n",
    "\n",
    "    # Start a timer\n",
    "    start = time.time()\n",
    "\n",
    "    # Run the query to get all contents from schema\n",
    "    query = pd.read_sql_query(\n",
    "        'SELECT medium, source, campaign, adcontent, keyword, usertype, devicecategory, '+\n",
    "        'pagepath_clean, pageviews, timeonpage, uniquepageviews, entrances, exits, bounces, report_date '+\n",
    "        'FROM '+schema+\".\"+table+\n",
    "        ' WHERE report_date BETWEEN %s AND %s AND application_display_name = %s;',\n",
    "        ENGINE, params=[\n",
    "            start_date, end_date,\n",
    "            'X']\n",
    "        )\n",
    "\n",
    "    return query, \"\\n Time it took in seconds: \" + str(time.time() - start)\n",
    "\n",
    "def get_schemas():\n",
    "    start = time.time()\n",
    "    schemas = pd.read_sql_query('select nspname from pg_namespace', ENGINE)\n",
    "    non_temp_schemas = schemas[~schemas['nspname'].str.contains('temp')]['nspname']\n",
    "    return non_temp_schemas, \"\\n Time it took in seconds: \" + str(time.time() - start)\n",
    "\n",
    "def care_and_conditions_grouping_function(data):\n",
    "    # Create group category names based on logic\n",
    "    grouping_levels = ['first level grouping', 'second level grouping']\n",
    "\n",
    "    start = time.time()\n",
    "    clean_stop_pagepath_clean = data['pagepath_clean'].str.split(pat=r'[?#\\., \\[\\]\\']')\n",
    "    split_pagepath_clean = clean_stop_pagepath_clean.str[0].str.split(pat=r'/')\n",
    "    \n",
    "    for i in range(len(grouping_levels)):\n",
    "        data[grouping_levels[i]] = split_pagepath_clean.str[i+1].str.replace('-', ' ').str.title()\n",
    "\n",
    "        df_counter = pd.DataFrame.from_dict(Counter(data[grouping_levels[i]]), orient='index').reset_index()\n",
    "        df_low = df_counter[df_counter[0] < 10]\n",
    "\n",
    "        data.loc[data[grouping_levels[i]].isin(df_low['index']), grouping_levels[i]] = \"Other\"\n",
    "        \n",
    "    data = data[data[grouping_levels[0]] == \"Conditions And Care Areas\"]\n",
    "    data = data.fillna(value=\"None\")\n",
    "\n",
    "    return data, \"\\n Time it took in seconds: \" + str(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Server Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User input\n",
    "SERVER = input(\"Server: \")\n",
    "DATABASE = input(\"Database: \")\n",
    "USERNAME = input(\"Username: \")\n",
    "PASSWORD = input(\"Password: \")\n",
    "PORT = input(\"Port: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ENGINE = create_engine(\n",
    "    'postgresql://'+USERNAME+':'+PASSWORD+'@'+SERVER+':'+PORT+'/'+DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Schema and Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Getting a list of schemas in the database\n",
    "\n",
    "schemas, schema_time = get_schemas()\n",
    "print(schemas.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# User input schema\n",
    "# Select one of the schemas above\n",
    "\n",
    "SCHEMA = input(\"Enter the schema desired: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting list of tables for a particular schema\n",
    "\n",
    "available_tables = pd.read_sql_query(\n",
    "    'select table_name from X where table_schema = %s;',\n",
    "        ENGINE, params=[\n",
    "            SCHEMA])\n",
    "print(available_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# USER INPUT\n",
    "# Select which table you want access to\n",
    "TABLE = input(\"Enter the table desired: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Filters, Groupings, Columns, Date Range, Update Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: find a more efficient way to get the column names\n",
    "# Right now, calling the first row and reading the columns instead of reading directly\n",
    "columns, columns_time = get_columns(SCHEMA, TABLE)\n",
    "print(columns)\n",
    "print(columns_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define empty column and dict\n",
    "grouping_column_list = []\n",
    "filters_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FILTERS HERE\n",
    "# These are chosen by user\n",
    "# Select a column to filter on, then select what columns you want to include\n",
    "\n",
    "# Filter by application display name mandatory, otherwise there is duplicate data\n",
    "filters_dict[\n",
    "    'application_display_name'] = 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GROUPINGS HERE\n",
    "# These are defined by us, need to request one for a client\n",
    "# User would decide on what to apply here, but they are not actually applied until after the data is pulled down\n",
    "\n",
    "# Columns that the user selects to be grouped on must be included in the initial query, but do not necessarily\n",
    "#need to be included in the final export. If they did not indicate keeping the columns, they can be deleted\n",
    "#from the dataframe before converting to a csv.\n",
    "\n",
    "care_and_conditions_grouping = True\n",
    "\n",
    "if care_and_conditions_grouping:\n",
    "    grouping_column_list.append('pagepath_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# USER INPUT\n",
    "# Select columns to interact with on the screen, data to pull in\n",
    "# Don't need to select columns just because we use them in where\n",
    "\n",
    "COLUMNS_FOR_TABLEAU = [\n",
    "    'medium', 'source', 'campaign', 'usertype', 'devicecategory', 'pagepath_clean', 'pageviews', 'report_date', 'timeonpage']\n",
    "\n",
    "# column_list needs to be a set becuase of the potential to add the same column many time for different requirement\n",
    "columns_list = set(grouping_column_list + COLUMNS_FOR_TABLEAU)\n",
    "START_DATE = datetime.date(2016, 8, 21)\n",
    "END_DATE = datetime.date(2017, 12, 31) # Possibly left blank to go to today\n",
    "\n",
    "UPDATE_DAILY = False # Only available if END_DATE is left blank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Queries and Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, data_time = get_data(SCHEMA, TABLE, columns_list, START_DATE, END_DATE, filters_dict)\n",
    "print(data)\n",
    "print(data_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['pageviews'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Custom Groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If the grouping was selected above, do this function\n",
    "if care_and_conditions_grouping:\n",
    "    data, care_and_conditions_grouping_time = care_and_conditions_grouping_function(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Consolidate columns for export so it only contains those desired\n",
    "data = data.drop(list(set(grouping_column_list) - set(COLUMNS_FOR_TABLEAU)), axis=1)\n",
    "\n",
    "# Export to csv\n",
    "start_csv_export = time.time()\n",
    "data.to_csv('tableau_example_extract.csv', index=False)\n",
    "time_csv_export = time.time() - start_csv_export\n",
    "print(time_csv_export)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
