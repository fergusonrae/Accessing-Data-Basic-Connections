{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "Connecting to redshift to pull down raw data is a common data need. This notebook aids this connection by prompting for required input. Resulting data is in a DataFrame format which can then be interacted with in the notebook or downloaded to a csv file for viewing and interaction off-notebook.\n",
    "\n",
    "Of note, if the dataset is extrememly large, there may be problems converting to csv. Chunking is a possible solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Server Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input\n",
    "SERVER = input(\"Server: \")\n",
    "DATABASE = input(\"Database: \")\n",
    "USERNAME = input(\"Username: \")\n",
    "PASSWORD = input(\"Password: \")\n",
    "PORT = input(\"Port: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGINE = create_engine(\n",
    "    'postgresql://'+USERNAME+':'+PASSWORD+'@'+SERVER+':'+PORT+'/'+DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = \"\"\n",
    "TABLE = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Specific data queries'''\n",
    "\n",
    "def get_columns(schema, table):\n",
    "    \"\"\"Returns alla available column names in the schema.table specified.\"\"\"    \n",
    "    query = pd.read_sql_query('SELECT TOP 1 * FROM '+schema+\".\"+table+';', ENGINE)\n",
    "    return query.columns\n",
    "\n",
    "# Currently, start_date and end_date are requriements for pulling down data\n",
    "# Thought is that extremely large datasets should not be pulled in just one query on a notebook\n",
    "# TODO: be adjusted to allow end_date to not be provided and be assumed to be current date\n",
    "def get_data(schema, table, start_date, end_date, columns=\"\", filters=\"\", like=\"\"):\n",
    "    \"\"\"Gets all data in the table provided, so long as it fits the filters and like attributes.\n",
    "    Returns a tuple\"\"\"\n",
    "    params_list = []\n",
    "    params_list.append(start_date)\n",
    "    params_list.append(end_date)\n",
    "    \n",
    "    # Select all columns, unless a list of columns has been passed as a parameter\n",
    "    if columns != \"\":\n",
    "        columns_as_string = ', '.join(columns)\n",
    "    else: columns_as_string = \"*\"\n",
    "    \n",
    "    if filters != \"\":\n",
    "        filters_query_list = []\n",
    "    \n",
    "        # Because there is already a filter requirement listed first (start_date and end_date)\n",
    "        # The string concat can begin with the word AND\n",
    "        for i in filters:\n",
    "            filters_query_list.append(' AND '+i+' IN ('+'%s,'*(len(filters[i])-1)+'%s)')\n",
    "            for j in filters[i]:\n",
    "                params_list.append(j)\n",
    "\n",
    "        filters_query_string = \"\".join(filters_query_list)\n",
    "    else: filters_query_string = \"\"\n",
    "    \n",
    "    if like != \"\":\n",
    "        for i in like:\n",
    "            filters_query_string += ' AND '+i+' LIKE %s'\n",
    "            params_list.append(like[i])\n",
    "    \n",
    "    query = \"\".join(['SELECT ', columns_as_string, ' FROM ', schema, \".\", table, \n",
    "                    ' WHERE report_date BETWEEN %s AND %s', filters_query_string, ';'])\n",
    "    \n",
    "    print('\\nThe query string is: ' + query)\n",
    "    data = pd.DataFrame()\n",
    "    for chunk in pd.read_sql_query(query, ENGINE, params=params_list, chunksize=10000):\n",
    "        data = data.append(chunk, ignore_index = True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_schemas():\n",
    "    \"\"\"Returns available schemas in the database.\"\"\"\n",
    "    schemas = pd.read_sql_query('select nspname from pg_namespace', ENGINE)\n",
    "    non_temp_schemas = schemas[~schemas['nspname'].str.contains('temp')]['nspname']\n",
    "    return non_temp_schemas\n",
    "    \n",
    "    \n",
    "\n",
    "def get_distinct_values(schema, table, column):\n",
    "    \"\"\"Return only unique values in the column.\"\"\"\n",
    "    query = pd.read_sql_query('SELECT DISTINCT '+column+' FROM '+schema+\".\"+table+';', ENGINE)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(SCHEMA, TABLE, START_DATE, END_DATE, filters=where_in_dict)\n",
    "#print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_NAME = input('Please input what you would like to name the file. Do not include the .csv ending.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(CSV_NAME + '.csv', index='None')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
